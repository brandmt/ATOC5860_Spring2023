{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ATOC5860 Application Lab #3 - eigenfaces\n",
    "##### Written by Dr. Vineel Yettella (ATOC Ph.D. 2018, now at Apple), with additional commenting from Prof. Kay (CU)\n",
    "##### last updated February 22, 2023 - works with environment atoc5860env2023clean.yml\n",
    "\n",
    "### LEARNING GOALS:\n",
    "1) Complete an EOF analysis using Singular Value Decomposition (SVD). \n",
    "2) Provide a qualitative description of the results. What are the eigenvalues, the eigenvectors, and the principal components?  What do you learn from each one about the space-time structure of your underlying dataset?\n",
    "3) Provide a qualitative description of the results: What are the eigenvalue,the eigenvector, and the principal component?  What do they mean physically? What do you learn from each one about the space-time structure of the underlying dataset?\n",
    "4) Reconstruct original data using a subset of EOFs: How many EOFs are needed to reconstruct faces?\n",
    "\n",
    "### DATA and UNDERLYING SCIENCE MOTIVATION:  \n",
    "In this notebook, you apply EOF analysis to a standard database for facial recognition: the At&t database. \n",
    "\n",
    "*“Our Database of Faces, (formerly 'The ORL Database of Faces'), contains a set of face images taken between April 1992 and April 1994 at the lab. The database was used in the context of a face recognition project carried out in collaboration with the Speech, Vision and Robotics Group of the Cambridge University Engineering Department.\n",
    "\n",
    "There are ten different images of each of 40 distinct subjects. For some subjects, the images were taken at different times, varying the lighting, facial expressions (open / closed eyes, smiling / not smiling) and facial details (glasses / no glasses). All the images were taken against a dark homogeneous background with the subjects in an upright, frontal position (with tolerance for some side movement).”*\n",
    "\n",
    "The goal is to think a bit “out of the box” of Atmospheric and Oceanic Sciences about potential applications for the methods you are learning in this class.  And also to think about some of the pitfalls of using statistics for facial recognition. Are the faces here representative of all faces?\n",
    "\n",
    "### Non-exhaustive Questions to guide your analysis:  \n",
    "1) Execute all code without making any modifications. What do the EOFs (spatial patterns) tell you?  What do the PCs tell you?  How do you interpret what you are finding?\n",
    "    - EOFs are\tthe\torthogonal\tspatial\tpatterns\twhich\texplain\tthe\ttemporal variance\tin\tour\tdataset.\tIn\tthis\texample,\tEOFs\trepresent\tthe\tunique\tfacial\tfeatures\twhich\texplain\tthe\tdifference\tbetween\tfaces.\tPrincipal\tcomponents\ttell\tus\tthe\tamplitude\tof\teach\tEOF\tacross\tthe\tsample\tdimension.\tSo\tin\tour\tcase\tEOFs\ttell\tus\tthe\tunique\tfacial\tfeatures\tand\tthe\tPCs\ttell\tus\t how\tstrong\teach\tof\tthose\tfeatures\tare\tacross\tthe\tdifferent\tphotos.\t\n",
    "\n",
    "2) Reconstruct a face.  How many EOFs do you need to reconstruct a face from the database?  Does it depend on the face that it used?\n",
    "    - For\ta man (face #35)\tI\tneed\tabout\t30\tEOFs\tto\trecreate it to an accuracy of 95% correlation,\twhereas\tfor\ta\twoman\t(face\t#340)\tI\tneed\tabout 100 EOFs. It highly depends on the face used, because some faces have more features that require less variance to recreate it, such as for a man. With less data for a woman's facial features, you require more EOFs to recreate it.\n",
    "\n",
    "3) Food for thought: The database contains 75% white men.  How do you think this database sampling limitation impacts the utility of the database for subjects who are not white men?  What are some parallels that you might draw when analyzing atmospheric and oceanic sciences datasets?  Hint: Think about the limitations of extrapolation beyond the domain where you have data.\n",
    "    - Not\tincluding\twoman\tor\tpeople\tof\tcolor\tmeans\tthat\tfeatures\twhich\texplain\tvariance in\twhite\tmen\tare\temphasized\tin\tthe\tEOFs\tover\tfeatures\twhich\texplain\tvariance\tin\tall\t people!\n",
    "    - Many arctic models rely on year-long observational data that can capture full seasonal cycles. However, it is hard to that and so far, very few data has been collected during a full seasonal cycle of the sea-ice in the arctic for example. This can result in some bias of the data. Most observations are done during the summer when the weather is much more favorable, and thus temporal extrapolation would miss a lot of crucial information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load faces. Adapted from the AT&T face database\n",
    "att_faces = np.load('att_faces.npy')\n",
    "height, width, n_faces = att_faces.shape\n",
    "print((height, width, n_faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(40, 1, figsize=(5,75))\n",
    "# for i,j in enumerate(range(0,400,10)):\n",
    "#     ax[i].imshow(att_faces[:, :, j], cmap='binary_r')\n",
    "#     ax[i].set_title('Face idx#: ' + str(j))\n",
    "#     ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print a few faces from the database - Look at your data!!\n",
    "n = 2\n",
    "fig, axs = plt.subplots(1, n)\n",
    "\n",
    "random_face_inds = np.random.choice(np.arange(n_faces), n, replace=False)\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.imshow(att_faces[:, :, random_face_inds[i]], cmap = 'gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the average face\n",
    "average_face = np.mean(att_faces, axis = 2);\n",
    "plt.imshow(average_face, cmap = 'gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct the data matrix. Samples (different faces) along rows and \n",
    "#variables (individual pixels) along columns\n",
    "print(att_faces.shape)\n",
    "data_matrix = np.reshape(att_faces, (height*width, n_faces)).T\n",
    "print(data_matrix.shape)\n",
    "\n",
    "#Construct anomaly matrix by removing the average face, i.e., \n",
    "#by removing the column means from each column of the data_matrix\n",
    "anomaly_matrix = data_matrix - np.mean(data_matrix, axis=0)\n",
    "#anomaly_matrix = anomaly_matrix/np.std(anomaly_matrix, axis=0)\n",
    "[eofs, s, v] = np.linalg.svd(anomaly_matrix.T, full_matrices=False)\n",
    "print(eofs.shape)\n",
    "\n",
    "eigenvals = np.square(s)\n",
    "variance_explained = eigenvals/np.sum(eigenvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the top 15 eofs (a.k.a eigenfaces)\n",
    "\n",
    "fig, axs = plt.subplots(3, 5)\n",
    "\n",
    "for i, ax in enumerate(np.reshape(axs, 15)):\n",
    "    eigenface = np.reshape(eofs[:, i], [height, width])\n",
    "    ax.imshow(eigenface, cmap='gray')\n",
    "    ax.set_title('eigenface' + str(i+1))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot variance explained by each eigenface\n",
    "plt.plot(variance_explained[0:100]*100, marker='o')\n",
    "plt.xlim(0,15)\n",
    "plt.ylim(bottom=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 75 #percent of variance retained\n",
    "\n",
    "ret_var = 0\n",
    "for i in range(len(variance_explained)):\n",
    "    ret_var = ret_var + variance_explained[i]*100\n",
    "    if ret_var > threshold:\n",
    "        print(f'{i+1} EOFs Needed')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project the faces onto the eigenfaces\n",
    "weights = np.dot(anomaly_matrix, eofs)\n",
    "print(weights.shape)\n",
    "\n",
    "#choose a face to reconstruct\n",
    "face_num = 340 #0 to 389\n",
    "original_face = att_faces[:, :, face_num]\n",
    "\n",
    "#choose number of weights to reconstruct face\n",
    "weights_num = 97\n",
    "face_weights = weights[face_num, 0:weights_num]\n",
    "print(face_weights.shape)\n",
    "reconstructed_face = np.dot(eofs[:, 0:weights_num], face_weights)\n",
    "\n",
    "#At this point, the reconstructed face is an anomaly face with the average face removed. \n",
    "#Add back the average face to get the original face\n",
    "\n",
    "reconstructed_face = np.reshape(reconstructed_face, (height, width)) + average_face\n",
    "print(reconstructed_face.shape)\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(original_face, cmap='gray');\n",
    "axs[1].imshow(reconstructed_face, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "threshold = 0.95 #correlation retained\n",
    "\n",
    "#choose a face to reconstruct\n",
    "face_num = 340 #0 to 389\n",
    "original_face = att_faces[:, :, face_num]\n",
    "og_face = xr.DataArray(original_face)\n",
    "\n",
    "for i in range(len(variance_explained)):\n",
    "    weights_num = i+1\n",
    "    face_weights = weights[face_num, 0:weights_num]\n",
    "    reconstructed_face = np.dot(eofs[:, 0:weights_num], face_weights)\n",
    "    reconstructed_face = np.reshape(reconstructed_face, (height, width)) + average_face\n",
    "    rc_face = xr.DataArray(reconstructed_face)\n",
    "    corr_face = xr.corr(og_face, rc_face).values\n",
    "    if corr_face > threshold:\n",
    "        print(f'{weights_num} EOFs Needed')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
